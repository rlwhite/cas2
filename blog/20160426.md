20160426
========
OK, just checking to see what to do next.

...

Test names
----------
So, we've got a few tests and planned tests which have pretty good names.  They're long, but they tell us pretty much what the test does.  It does occur to me, though, that those first few test names were pretty lame: *PassingTestTest*, *FailingTestTest*, and *SkippedTestTest*?  I think *PassingTest*, *FailingTest*, and *SkippedTest* are probably OK, but the others should be better.  The names make us think the are all incompassing, when in fact, I believe we may have some wholes there.  So, before we complete our other tests, I think we should revisit these.

*PassingTestTest* -> *PassingTestThrowsNoExceptions*
----------------------------------------------------
Since, in *casTest* a passing test is in essence a test which throws no exceptions, the name should probably state that.  So, we'll begin by changing the name.

>_Side Note_:
>
>It's probably getting to be time to split some of this code into other files, including proper header and implementation files.  We will do that soon, but for now, we'll keep cleaning up these tests.

...

Everything still passes.  Now we'll rename *FailingTestTest* to *FailedTestThrowsTestFailed*, and *SkippedTestTest* to *SkippedTestThrowsTestSkipped*.

...

Everything still passes.  As I was renaming these tests, I also took the opportunity to ensure that each test would fail if the expected bahavior was not met.  For *PassingTestThrowsNoExceptions*, I simply threw an exception from *PassingTest*.  Once I had the failure, I changed it back to its non-throwing version.  For both *FailedTestThrowsTestFailed* and *SkippedTestThrowsTestSkipped*, I simply commented out the throws from *FailingTest* and *SkippedTest*.  I restored the throwing versions once I had a proper failing test.

A little more refactoring
-------------------------
*TestRunner::runTests()* has got an awful lot going on.  First, of course it's iterating over a collection of tests.  It's building a report of the results of the tests.  (That part will stay for the time being, but we'll create a proper test reporter soon.)  We're also trying each test we're iterating over, catching any exceptions along the way.  So....

First, we'll create a function to handle any exceptions the a test may throw.  We'll call it *tryTest()*.

I'd like to turn that for loop into a range-based for loop.  I'll need to add a local or a member to track the test "number" though.  I guess that's easy enough.

That looks pretty good, and everything still passes.

...

It's getting late.  More to follow.

>*Note to self*:  Consider *TestLogger*.  Can run a single test and return a fully constructed string with the results.

valgrind
--------
	==1235== Memcheck, a memory error detector
	==1235== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al.
	==1235== Using Valgrind-3.10.1 and LibVEX; rerun with -h for copyright info
	==1235== Command: ./casTest
	==1235== 
	Running 4 tests.
		1. PassingTestThrowsNoExceptions: OK
		2. FailingTestThrowsTestFailed: OK
		3. SkippedTestThrowsTestSkipped: OK
	Running 3 tests.
		1. PassingTest: OK
		2. FailingTest: NOT OK
		3. SkippedTest: SKIPPED
	One or more tests FAILED (One or more tests SKIPPED)
	    4. TestRunnerReportsAFailureWhenATestFails: OK
	All tests PASSED
	==1235== 
	==1235== HEAP SUMMARY:
	==1235==     in use at exit: 0 bytes in 0 blocks
	==1235==   total heap usage: 27 allocs, 27 frees, 1,219 bytes allocated
	==1235== 
	==1235== All heap blocks were freed -- no leaks are possible
	==1235== 
	==1235== For counts of detected and suppressed errors, rerun with: -v
	==1235== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)
