#20160522#

OK, so I think I know how I want the exceptions be coded.  After looking at how *Catch* defines its test case failures, I was tempted to just change *TestCase::TestFailed* to accept a message and be done with it.  However, I do think that maybe the actual formatting of the error messages should be handled near the code that catches the exceptions, rather than having the assert macro build the strings.  I'm not totally sold on this idea, but that's the way I will go for now.  I might even create a class whose sole responsibility is to translate exception objects into a printable/loggable message.  So, adding an  item to the task list.

**TODO**
--------
* TestRunner tests:

>* <del>PassingTestThrowsNoExceptions</del>
>* <del>FailingTestThrowsTestFailed</del>
>* <del>SkippedTestThrowsTestSkipped</del>
>* <del>TestRunnerReportsNoFailuresWhenAllTestsPass</del>
>* TestRunnerReportsNoFailuresWhenAllTestsSkipped
>* TestRunnerReportsSkipWhenTestIsSkipped
>* TestRunnerReportsNoSkipsWhenAllTestsPass
>* TestRunnerReportsNoSkipsWhenAllTestsFail
>* <del>TestRunnerReportsNoFailuresWhenAllTestsPassOrSkip</del>
>* TestRunnerReportsNoSkipsWhenAllTestsPassOrFail

* TestReporter tests:
>* <del>TestReporterPrintsOKForPassedTest</del>
>* <del>TestReporterPrintsTestPlan</del>
>* <del>TestReporterPrintsNOTOKForFailedTest</del>
>* <del>TestReporterPrintsSKIPPEDForSkippedTest</del>
>* <del>TestReporterPrintsTestSummary</del>

* <del>Split the code into multiple files</del>
* <del>Refactor *TestRunner::runTest()*.  Should *tryTest()* return the test result (PASS, FAIL, SKIP) ?</del>
* <del>Create test logger/reporter.  How should we format the report?  Use TAP-style output?</del>
* Implement various assert macros for test writers
  **-- Create an error message factory that translates exception objects into
       error messages**
* Implement test construction macros

* Rework the make system to be fully independent
* Consider whether or not *casTest* should be built into a single executable tool (rather than multiple tools).
* Consider replace *out_* member of *TestReporter* with something else.

##Test Exceptions - A start##

The first thing to do is to address the exception classes that need to be created.  I'll start by writing a test for verifying that we can log the source file and line number.  We'll add this and the related tests to *testExceptionTests.cpp.  I fully except to have to refactor some code along the way.

...

OK, so we now capture the source and line number at the point of the throw.  All tests pass.  Now I think I'd like to create a macro to make capturing source and line info automatic.  This macro will also take a bool as the first argument allowing an expression to be passed.  We'll change this as we go, but this should be a nice start.  We don't need a test for this as this is essentially refactoring.  I'll change one test to make sure the marco works, then will replace all the places we compare and throw with the macro.

...

*EXPECT_TRUE* has been implemented and all tests pass.  Next, I'll implement *EXPECT_FALSE* and *EXPECT_THROWS*.  Hmmm, I don't have a good place to use *EXPECT_FALSE*.  Since it's just the compliment of *EXPECT_TRUE*, I'll implement it any way.  (This feels a little like cheating.)

...

OK, those 3 macros are complete and are now being used in our built-in tests.  Well, *EXPECT_TRUE* and *EXPECT_THROWS* any way.

...

I'm not sure we'll get away with not having the error message being created at the time of an exception throw.  It seems that by not having the message contained in the exception, we wouldn't be able to use polymorphic dispatch when reporting test exceptions.  I guess we'll see how it goes.

Another short day.  (I wasted too much time.)

So, here's the valgrind report:

##valgrind##
	==26270== Memcheck, a memory error detector
	==26270== Copyright (C) 2002-2013, and GNU GPL'd, by Julian Seward et al.
	==26270== Using Valgrind-3.10.1 and LibVEX; rerun with -h for copyright info
	==26270== Command: ./casTest
	==26270== 
	1..12
	ok 1 - PassingTestThrowsNoExceptions
	ok 2 - FailingTestThrowsTestFailed
	ok 3 - SkippedTestThrowsTestSkipped
	ok 4 - TestRunnerReportsNoFailuresWhenAllTestsPass
	ok 5 - TestRunnerReportsAFailureWhenATestFails
	ok 6 - TestRunnerReportsNoFailuresWhenAllTestsPassOrSkip
	ok 7 - TestReporterPrintsTestPlan
	ok 8 - TestReporterPrintsOKForPassedTest
	ok 9 - TestReporterPrintsNOTOKForFailedTest
	ok 10 - TestReporterPrintsSKIPPEDForSkippedTest
	ok 11 - TestReporterPrintsTestSummary
	ok 12 - TestExceptionContainsFileAndLineInfo
	Tests ran: 12
	FAILED: 0
	SKIPPED: 0
	==26270== 
	==26270== HEAP SUMMARY:
	==26270==     in use at exit: 0 bytes in 0 blocks
	==26270==   total heap usage: 98 allocs, 98 frees, 8,179 bytes allocated
	==26270== 
	==26270== All heap blocks were freed -- no leaks are possible
	==26270== 
	==26270== For counts of detected and suppressed errors, rerun with: -v
	==26270== ERROR SUMMARY: 0 errors from 0 contexts (suppressed: 0 from 0)








